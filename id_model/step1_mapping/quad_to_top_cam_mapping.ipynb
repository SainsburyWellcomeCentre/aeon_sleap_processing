{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image registration to create a pixel map between top camera (A) and quadrant camera (B) with overlapping fields of view (FOV), where quadtant camera's FOV is a subset and a rotated version of top camera's FOV. \n",
    "1. Exrtact and Load Images: Dynamically extract random matching frames from the video frames for both Camera A and Camera B.\n",
    "2. Detect Features: Use ORB (Oriented FAST and Rotated BRIEF) to detect keypoints and get descriptors. \n",
    "3. Match Features: Use a matcher (rute-Force matcher with Hamming distance) to find corresponding keypoints between the images. Keep best matches.\n",
    "4. Compute Homography: Estimate the homography matrix (matrix that best transforms the matched keypoints from Camera B's frame of reference to Camera A's frame of reference) to align the images (rotation, translation, scaling).\n",
    "5. Pixel map: Get the pixel map from A to B and vice versa based on this.\n",
    "6. Quality checks base on homography matrix.\n",
    "7. Multi-frame averaging: Perform these computation on many frames and average over individual homography matrices that pass checks for more accurate results.\n",
    "8. Visualise results by applying the homography to transform Camera B's images to align with Camera A's perspective.\n",
    "9. Save map, H, and visualisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method seems to work better then other tried, becasue:\n",
    "\n",
    "- can deal with low number of unique features in the image (feature matching algorithms failed)\n",
    "- can deal with orientation and perspective differences (template matching (= find B within A) failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homography matrix explanation:\n",
    "\n",
    "- ( h_{11} ) and ( h_{22} ): These elements represent scaling and rotation. They affect how the image is scaled and rotated around the origin.\n",
    "- ( h_{12} ) and ( h_{21} ): These elements represent shear. They affect how the image is skewed.\n",
    "- ( h_{13} ) and ( h_{23} ): These elements represent translation. They affect how the image is shifted in the x and y directions.\n",
    "- ( h_{31} ) and ( h_{32} ): These elements represent perspective distortion. They affect how the image is warped to simulate a change in viewpoint.\n",
    "- ( h_{33} ): This element is typically 1 for normalization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"Define constants\"\"\"\n",
    "# this shoud be run for each experiment and arena (on a random chunk at start of experiment)\n",
    "\n",
    "# experiment = 'social0.2'\n",
    "# arena = 'AEON3'\n",
    "# run_start = '2024-01-31T10-28-39'\n",
    "# chunk_start = '2024-01-31T11-00-00'\n",
    "\n",
    "# experiment = 'social0.2'\n",
    "# arena = 'AEON4'\n",
    "# run_start = '2024-02-09T16-39-14'\n",
    "# chunk_start = '2024-02-10T11-00-00'\n",
    "\n",
    "# experiment = 'social0.3'\n",
    "# arena = 'AEON3'\n",
    "# run_start = '2024-06-09T10-03-46'\n",
    "# chunk_start = '2024-06-10T16-00-00'\n",
    "\n",
    "# experiment = 'social0.3'\n",
    "# arena = 'AEON4'\n",
    "# run_start = '2024-06-08T18-27-09'\n",
    "# chunk_start = '2024-06-12T10-00-00'\n",
    "\n",
    "# experiment = 'social0.4'\n",
    "# arena = 'AEON3'\n",
    "# run_start = '2024-08-28T10-09-33'\n",
    "# chunk_start = '2024-08-28T14-00-00'\n",
    "\n",
    "experiment = 'social0.4'\n",
    "arena = 'AEON4'\n",
    "run_start = '2024-08-16T14-30-28'\n",
    "chunk_start = '2024-08-18T14-00-00'\n",
    "\n",
    "camera_a = 'CameraTop'\n",
    "camera_b_list = ['CameraSouth', 'CameraNorth', 'CameraEast', 'CameraWest']\n",
    "base_path = '/ceph/aeon/aeon'\n",
    "video_path = base_path + f'/data/raw/{arena}/{experiment}/{run_start}'\n",
    "video_path_a = video_path + f'/{camera_a}/{camera_a}_{chunk_start}.avi'\n",
    "results_dir = base_path + f'/code/scratchpad/Orsi/pixel_mapping/pixel_mapping_results/{experiment}/{arena}'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\"\"\"Define utility functions\"\"\"\n",
    "def extract_frame(cap, frame_idx):\n",
    "    \"\"\"Extract a single frame from the video at the given index.\"\"\"\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "    ret, frame = cap.read()\n",
    "    return frame if ret else None\n",
    "\n",
    "def save_plot(img_a, img_b, img_b_aligned, kp_a, kp_b, matches, mask, title, save_path):\n",
    "    \"\"\"Save the final plot with warping based on average H.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_a, cmap='gray')\n",
    "    plt.title(\"Camera A (Original)\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(img_b, cmap='gray')\n",
    "    plt.title(\"Camera B (Original)\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(img_b_aligned, cmap='gray')\n",
    "    plt.title(\"Camera B (Aligned to A)\")\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "def warp_image(img_b, H, img_a_shape):\n",
    "    \"\"\"\n",
    "    Warp Image B to Image A's perspective using the homography matrix.\n",
    "    \"\"\"\n",
    "    # Apply homography to warp Image B\n",
    "    img_b_aligned = cv2.warpPerspective(img_b, H, (img_a_shape[1], img_a_shape[0]))\n",
    "    return img_b_aligned\n",
    "\n",
    "def save_homography_and_maps(H, map_a_to_b, map_b_to_a, camera_b):\n",
    "    \"\"\"Save the homography matrix and pixel maps.\"\"\"\n",
    "    np.save(os.path.join(results_dir, f'H_{camera_b}.npy'), H)\n",
    "    np.save(os.path.join(results_dir, f'map_a_to_b_{camera_b}.npy'), map_a_to_b)\n",
    "    np.save(os.path.join(results_dir, f'map_b_to_a_{camera_b}.npy'), map_b_to_a)\n",
    "    print(f\"Saved homography and pixel maps for {camera_b}.\")\n",
    "\n",
    "def calculate_pixel_mapping(kp_a, kp_b, H, img_shape):\n",
    "    \"\"\"Calculate pixel mappings between two images.\"\"\"\n",
    "    # Create empty maps for the pixel correspondence\n",
    "    map_a_to_b = np.zeros((img_shape[0], img_shape[1], 2), dtype=np.float32)\n",
    "    map_b_to_a = np.zeros((img_shape[0], img_shape[1], 2), dtype=np.float32)\n",
    "\n",
    "    # Calculate the pixel mapping\n",
    "    for y in range(img_shape[0]):\n",
    "        for x in range(img_shape[1]):\n",
    "            # Map from A to B\n",
    "            pt_a = np.array([[x, y]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "            pt_b = cv2.perspectiveTransform(pt_a, H)\n",
    "            map_a_to_b[y, x] = pt_b[0, 0]\n",
    "\n",
    "            # Map from B to A\n",
    "            pt_b_inv = cv2.perspectiveTransform(pt_b, np.linalg.inv(H))\n",
    "            map_b_to_a[y, x] = pt_b_inv[0, 0]\n",
    "\n",
    "    return map_a_to_b, map_b_to_a\n",
    "\n",
    "def process_video_frames(video_path_a, video_path_b, camera_b, num_good_frames=50):\n",
    "    \"\"\"Process frames from two videos dynamically until 20 good frames are found.\"\"\"\n",
    "    cap_a = cv2.VideoCapture(video_path_a)\n",
    "    cap_b = cv2.VideoCapture(video_path_b)\n",
    "\n",
    "    total_frames = int(cap_a.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    good_homographies = []\n",
    "    frames_checked = 0\n",
    "\n",
    "    while len(good_homographies) < num_good_frames:\n",
    "        frame_idx = random.randint(0, total_frames - 1)  # Randomly select a frame index\n",
    "\n",
    "        # Extract frames for both cameras\n",
    "        frame_a = extract_frame(cap_a, frame_idx)\n",
    "        frame_b = extract_frame(cap_b, frame_idx)\n",
    "\n",
    "        if frame_a is None or frame_b is None:\n",
    "            print(f\"Could not read frames at index {frame_idx}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Convert frames to grayscale\n",
    "        img_a = cv2.cvtColor(frame_a, cv2.COLOR_BGR2GRAY)\n",
    "        img_b = cv2.cvtColor(frame_b, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect and match features\n",
    "        kp_a, kp_b, matches = detect_and_match_features(img_a, img_b)\n",
    "        if len(matches) < 4:  # Not enough matches to compute a homography\n",
    "            print(\"Not enough matches. Skipping frame...\")\n",
    "            continue\n",
    "\n",
    "        # Compute homography\n",
    "        H, mask = compute_homography(kp_a, kp_b, matches)\n",
    "\n",
    "        if H is not None and is_perspective_good(H) and is_rotation_good(H, camera_b) and is_shear_good(H):\n",
    "            good_homographies.append(H)\n",
    "            print(f\"Valid Homography found for frame index {frame_idx} (total valid: {len(good_homographies)})\")\n",
    "        else:\n",
    "            print(f\"Invalid Homography at frame index {frame_idx}.\")\n",
    "\n",
    "    cap_a.release()\n",
    "    cap_b.release()\n",
    "    \n",
    "    if len(good_homographies) < num_good_frames:\n",
    "        print(f\"Analysis could not complete for {camera_b}. Checked {frames_checked} frames but found only {len(good_homographies)} good homographies.\")\n",
    "        return None, None\n",
    "\n",
    "    # Compute the average homography\n",
    "    H_avg = np.mean(good_homographies, axis=0)\n",
    "    print(f\"Averaged Homography:\\n{H_avg} based on {len(good_homographies)} valid homographies.\")\n",
    "\n",
    "    # Use the last valid frames for final plotting\n",
    "    img_b_aligned = warp_image(img_b, H_avg, img_a.shape)\n",
    "\n",
    "    # Calculate pixel maps\n",
    "    map_a_to_b, map_b_to_a = calculate_pixel_mapping(kp_a, kp_b, H_avg, img_a.shape)\n",
    "\n",
    "    # Save results\n",
    "    save_plot(img_a, img_b, img_b_aligned, kp_a, kp_b, matches, mask, 'Final Averaged Homography',\n",
    "              os.path.join(results_dir, f'final_plot_{camera_b}.png'))\n",
    "    save_homography_and_maps(H_avg, map_a_to_b, map_b_to_a, camera_b)\n",
    "\n",
    "    return H_avg, good_homographies\n",
    "\n",
    "def detect_and_match_features(img_a, img_b, nfeatures=1000):\n",
    "    \"\"\"Detect and match features between two images using ORB.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures)\n",
    "    kp_a, des_a = orb.detectAndCompute(img_a, None)\n",
    "    kp_b, des_b = orb.detectAndCompute(img_b, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des_a, des_b)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return kp_a, kp_b, matches\n",
    "\n",
    "def compute_homography(kp_a, kp_b, matches):\n",
    "    \"\"\"Compute the homography matrix to map Image B to Image A.\"\"\"\n",
    "    src_pts = np.float32([kp_b[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp_a[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return H, mask\n",
    "\n",
    "def is_perspective_good(H, perspective_threshold=1e-3):\n",
    "    \"\"\"Check if the homography matrix is good based on perspective distortion.\"\"\"\n",
    "    h31, h32 = H[2, 0], H[2, 1]\n",
    "    return abs(h31) <= perspective_threshold and abs(h32) <= perspective_threshold\n",
    "\n",
    "def is_shear_good(H, shear_threshold=1):\n",
    "    \"\"\"Check if the homography matrix is good based on shearing distortion.\"\"\"\n",
    "    h12, h21 = H[0, 1], H[1, 0]\n",
    "    return abs(h12) <= shear_threshold and abs(h21) <= shear_threshold\n",
    "\n",
    "def is_rotation_good(H, camera_b, tolerance=15):\n",
    "    \"\"\"Check if the homography matrix has a rotation component within the expected range.\"\"\"\n",
    "    R = H[0:2, 0:2]\n",
    "    theta = np.arctan2(R[1, 0], R[0, 0]) * 180 / np.pi\n",
    "    theta = theta % 360\n",
    "\n",
    "    if camera_b == 'CameraWest':\n",
    "        expected_rotation = 0\n",
    "    elif camera_b == 'CameraNorth':\n",
    "        expected_rotation = 90\n",
    "    elif camera_b == 'CameraEast':\n",
    "        expected_rotation = 180\n",
    "    elif camera_b == 'CameraSouth':\n",
    "        expected_rotation = 270\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized camera_b: {camera_b}\")\n",
    "\n",
    "    circular_difference = min(abs(theta - expected_rotation), 360 - abs(theta - expected_rotation))\n",
    "    return circular_difference <= tolerance\n",
    "\n",
    "\"\"\"Run dynamic extraction and processing for all CameraBs\"\"\" \n",
    "for camera_b in camera_b_list:\n",
    "    video_path_b = video_path + f'/{camera_b}/{camera_b}_{chunk_start}.avi'\n",
    "    print(f\"Processing frames for Camera B: {camera_b}\")\n",
    "    H_avg, homographies = process_video_frames(video_path_a, video_path_b, camera_b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "aeon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
